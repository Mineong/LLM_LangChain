from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain.chains import RetrievalQA

print("==> 1. ë¬¸ì„œ ë¡œë”© â†’ PDF ì½ê¸°...")
loader = PyPDFLoader('./data/tutorial-korean.pdf')
documents = loader.load()
print(f"  ì´ {len(documents)}í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")

print("==> 2. ë¬¸ì„œ ë¶„í•  â†’ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,
    chunk_overlap=150,
    separators=["\n\n", "\n", ".", " ", ""]
)
chunks = text_splitter.split_documents(documents)
print(f"  {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")

print("==> 3. ë²¡í„°í™” â†’ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜")
embeddings = OllamaEmbeddings(
    model="qwen3:1.7b",
    base_url="http://localhost:11434"
)

print("==> 4. ì €ì¥ â†’ FAISS ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥")
vectorstore = FAISS.from_documents(chunks, embeddings)

print("===> 5. ê²€ìƒ‰ â†’ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°")
retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 4}
)

print("===> 6. ìƒì„± â†’ LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±")
llm = ChatOllama(
    model="qwen3:1.7b",
    base_url="http://localhost:11434",
    temperature=0.1,
    num_predict=1500
)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

query = "ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?"
result = qa_chain.invoke(query)

print("\n[ğŸ” ì§ˆì˜ ê²°ê³¼]")
print(result["result"])
print("\n[ğŸ“„ ì°¸ê³  ë¬¸ì„œ]")
for doc in result["source_documents"]:
    print(f"- {doc.metadata['source']}")
