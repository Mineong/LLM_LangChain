{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0503db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "with open(\"./data/cafe_menu.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\\\n",
    "ë©”ë‰´ë²ˆí˜¸: 1\n",
    "ì´ë¦„: ì•„ë©”ë¦¬ì¹´ë…¸\n",
    "ê°€ê²©: â‚©4,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ëœ¨ê±°ìš´ ë¬¼\n",
    "ì„¤ëª…: ì›ë‘ ë³¸ì—°ì˜ ë§›ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê¸°ë³¸ ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 2\n",
    "ì´ë¦„: ì¹´í˜ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ \n",
    "ì„¤ëª…: ë¶€ë“œëŸ½ê³  ê³ ì†Œí•œ ë§›ì˜ ë°€í¬ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 3\n",
    "ì´ë¦„: ë°”ë‹ë¼ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , ë°”ë‹ë¼ ì‹œëŸ½\n",
    "ì„¤ëª…: ë‹¬ì½¤í•œ ë°”ë‹ë¼ í–¥ì´ ê°€ë¯¸ëœ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 4\n",
    "ì´ë¦„: ì½œë“œë¸Œë£¨\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì½œë“œë¸Œë£¨ ì›ì•¡, ë¬¼\n",
    "ì„¤ëª…: ê¹”ë”í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§›ì˜ ì°¨ê°€ìš´ ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 5\n",
    "ì´ë¦„: í—¤ì´ì¦ë„›ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , í—¤ì´ì¦ë„› ì‹œëŸ½\n",
    "ì„¤ëª…: ê³ ì†Œí•˜ê³  ë‹¬ì½¤í•œ ë§›ì˜ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 6\n",
    "ì´ë¦„: ì¹´í‘¸ì¹˜ë…¸\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ  ê±°í’ˆ\n",
    "ì„¤ëª…: í’ë¶€í•œ ê±°í’ˆê³¼ ì§„í•œ ì»¤í”¼ì˜ ì¡°í™”\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 7\n",
    "ì´ë¦„: ë§ì°¨ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,800\n",
    "ì¬ë£Œ: ë§ì°¨, ìš°ìœ \n",
    "ì„¤ëª…: ìŒ‰ì‹¸ë¦„í•œ ë§ì°¨ì™€ ìš°ìœ ì˜ ì¡°í™”\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 8\n",
    "ì´ë¦„: í† í”¼ë„›ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,800\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , í† í”¼ë„› ì‹œëŸ½\n",
    "ì„¤ëª…: ë‹¬ì½¤í•˜ê³  ê³ ì†Œí•œ ê²¬ê³¼ë¥˜ í’ë¯¸ì˜ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 9\n",
    "ì´ë¦„: ë¯¼íŠ¸ì´ˆì½”ë¼ë–¼\n",
    "ê°€ê²©: â‚©6,000\n",
    "ì¬ë£Œ: ìš°ìœ , ë¯¼íŠ¸ ì‹œëŸ½, ì´ˆì½” ì‹œëŸ½\n",
    "ì„¤ëª…: ìƒì¾Œí•œ ë¯¼íŠ¸ì™€ ì§„í•œ ì´ˆì½”ì˜ ë§Œë‚¨\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 10\n",
    "ì´ë¦„: ë”¸ê¸°ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ìš°ìœ , ë”¸ê¸°ì²­\n",
    "ì„¤ëª…: ìƒí¼í•œ ë”¸ê¸°ì˜ í–¥ê³¼ ë¶€ë“œëŸ¬ìš´ ìš°ìœ \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726f9bc",
   "metadata": {},
   "source": [
    "### ë¬¸ì œ 5-1 : ì¹´í˜ ë©”ë‰´ ë„êµ¬(Tool) í˜¸ì¶œ ì²´ì¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459adfcc",
   "metadata": {},
   "source": [
    "#### 1. ì¹´í˜ ë©”ë‰´ ë°ì´í„° íŒŒì¼ ìƒì„± ë° ë²¡í„° DB êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2cabc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1. cafe_menu.txt ìƒì„± (10ê°œ ë©”ë‰´ í•­ëª©)\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "with open(\"./data/cafe_menu.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\"\"\\\n",
    "ë©”ë‰´ë²ˆí˜¸: 1\n",
    "ì´ë¦„: ì•„ë©”ë¦¬ì¹´ë…¸\n",
    "ê°€ê²©: â‚©4,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ëœ¨ê±°ìš´ ë¬¼\n",
    "ì„¤ëª…: ì›ë‘ ë³¸ì—°ì˜ ë§›ì„ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê¸°ë³¸ ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 2\n",
    "ì´ë¦„: ì¹´í˜ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ \n",
    "ì„¤ëª…: ë¶€ë“œëŸ½ê³  ê³ ì†Œí•œ ë§›ì˜ ë°€í¬ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 3\n",
    "ì´ë¦„: ë°”ë‹ë¼ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , ë°”ë‹ë¼ ì‹œëŸ½\n",
    "ì„¤ëª…: ë‹¬ì½¤í•œ ë°”ë‹ë¼ í–¥ì´ ê°€ë¯¸ëœ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 4\n",
    "ì´ë¦„: ì½œë“œë¸Œë£¨\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì½œë“œë¸Œë£¨ ì›ì•¡, ë¬¼\n",
    "ì„¤ëª…: ê¹”ë”í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§›ì˜ ì°¨ê°€ìš´ ì»¤í”¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 5\n",
    "ì´ë¦„: í—¤ì´ì¦ë„›ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , í—¤ì´ì¦ë„› ì‹œëŸ½\n",
    "ì„¤ëª…: ê³ ì†Œí•˜ê³  ë‹¬ì½¤í•œ ë§›ì˜ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 6\n",
    "ì´ë¦„: ì¹´í‘¸ì¹˜ë…¸\n",
    "ê°€ê²©: â‚©5,000\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ  ê±°í’ˆ\n",
    "ì„¤ëª…: í’ë¶€í•œ ê±°í’ˆê³¼ ì§„í•œ ì»¤í”¼ì˜ ì¡°í™”\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 7\n",
    "ì´ë¦„: ë§ì°¨ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,800\n",
    "ì¬ë£Œ: ë§ì°¨, ìš°ìœ \n",
    "ì„¤ëª…: ìŒ‰ì‹¸ë¦„í•œ ë§ì°¨ì™€ ìš°ìœ ì˜ ì¡°í™”\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 8\n",
    "ì´ë¦„: í† í”¼ë„›ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,800\n",
    "ì¬ë£Œ: ì—ìŠ¤í”„ë ˆì†Œ, ìš°ìœ , í† í”¼ë„› ì‹œëŸ½\n",
    "ì„¤ëª…: ë‹¬ì½¤í•˜ê³  ê³ ì†Œí•œ ê²¬ê³¼ë¥˜ í’ë¯¸ì˜ ë¼ë–¼\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 9\n",
    "ì´ë¦„: ë¯¼íŠ¸ì´ˆì½”ë¼ë–¼\n",
    "ê°€ê²©: â‚©6,000\n",
    "ì¬ë£Œ: ìš°ìœ , ë¯¼íŠ¸ ì‹œëŸ½, ì´ˆì½” ì‹œëŸ½\n",
    "ì„¤ëª…: ìƒì¾Œí•œ ë¯¼íŠ¸ì™€ ì§„í•œ ì´ˆì½”ì˜ ë§Œë‚¨\n",
    "\n",
    "ë©”ë‰´ë²ˆí˜¸: 10\n",
    "ì´ë¦„: ë”¸ê¸°ë¼ë–¼\n",
    "ê°€ê²©: â‚©5,500\n",
    "ì¬ë£Œ: ìš°ìœ , ë”¸ê¸°ì²­\n",
    "ì„¤ëª…: ìƒí¼í•œ ë”¸ê¸°ì˜ í–¥ê³¼ ë¶€ë“œëŸ¬ìš´ ìš°ìœ \n",
    "\"\"\")\n",
    "\n",
    "# 2. í…ìŠ¤íŠ¸ â†’ Document ë¡œë“œ ë° ë¶„í• \n",
    "loader = TextLoader(\"./data/cafe_menu.txt\", encoding=\"utf-8\")\n",
    "raw_docs = loader.load()\n",
    "\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=300, chunk_overlap=0)\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "\n",
    "# 3. ë²¡í„°í™” ë° DB ì €ì¥\n",
    "embedding_model = OllamaEmbeddings(model=\"bge-m3\")\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)\n",
    "vectorstore.save_local(\"./db/cafe_db\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dca94a",
   "metadata": {},
   "source": [
    "#### 2. 3ê°œì˜ ë„êµ¬ë¥¼ ì •ì˜í•˜ê³  LLMì— ë°”ì¸ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4341efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# a) tavily_search_func - ì›¹ ê²€ìƒ‰ ë„êµ¬\n",
    "tavily_search_func = TavilySearchResults(k=3)\n",
    "\n",
    "# b) wiki_summary - ìœ„í‚¤ë°±ê³¼ ìš”ì•½ ë„êµ¬\n",
    "@tool\n",
    "def wiki_summary(query: str) -> str:\n",
    "    \"\"\"ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ì¼ë°˜ ì§€ì‹ì„ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.\"\"\"\n",
    "    docs = WikipediaLoader(query=query, lang=\"ko\").load()\n",
    "    return \"\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# c) db_search_cafe_func - ë¡œì»¬ ë²¡í„° DB ê²€ìƒ‰ ë„êµ¬\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> str:\n",
    "    \"\"\"ì¹´í˜ ë©”ë‰´ ì •ë³´ë¥¼ ë²¡í„° DBì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\"\"\"\n",
    "    vectorstore = FAISS.load_local(\"./db/cafe_db\", OllamaEmbeddings(model=\"bge-m3\"))\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", k=3)\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    if not results:\n",
    "        return \"ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    return \"\\n\".join([f\"- {doc.page_content}\" for doc in results])\n",
    "\n",
    "# âœ… LLM ë°”ì¸ë”©\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools([\n",
    "    tavily_search_func,\n",
    "    wiki_summary,\n",
    "    db_search_cafe_func\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69728e",
   "metadata": {},
   "source": [
    "#### 3. ê°„ë‹¨í•œ ë„êµ¬ í˜¸ì¶œ ì²´ì¸ êµ¬í˜„ì²´ì¸ êµ¬ì¡°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dc8aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain, RunnableConfig\n",
    "\n",
    "# 1. í”„ë¡¬í”„íŠ¸ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹´í˜ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ë„êµ¬ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:\\n{tool_messages}\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 2. ë„êµ¬ í˜¸ì¶œ ë° ê²°ê³¼ ì¢…í•© ì²´ì¸\n",
    "@chain\n",
    "def cafe_tool_chain(user_input: str, config: RunnableConfig):\n",
    "    # (1) ì‚¬ìš©ì ì§ˆë¬¸ â†’ ë„êµ¬ ì„ íƒ\n",
    "    ai_msg = (prompt | llm_with_tools).invoke({\"input\": user_input}, config=config)\n",
    "\n",
    "    # âœ… ë„êµ¬ í˜¸ì¶œ ë¦¬ìŠ¤íŠ¸ í™•ì¸\n",
    "    print(\"ğŸ” ì„ íƒëœ ë„êµ¬ ëª©ë¡:\", ai_msg.tool_calls)\n",
    "\n",
    "    # (2) ë„êµ¬ ì‹¤í–‰\n",
    "    tool_messages = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "\n",
    "        if tool_name == \"db_search_cafe_func\":\n",
    "            tool_messages.append(db_search_cafe_func.invoke(tool_args))\n",
    "        elif tool_name == \"wiki_summary\":\n",
    "            tool_messages.append(wiki_summary.invoke(tool_args))\n",
    "        elif tool_name == \"tavily_search\":\n",
    "            tool_messages.append(tavily_search_func.invoke(tool_args))\n",
    "\n",
    "    # âœ… ë„êµ¬ ê²°ê³¼ í™•ì¸\n",
    "    print(\"ğŸ§¾ ë„êµ¬ ì‹¤í–‰ ê²°ê³¼:\", tool_messages)\n",
    "\n",
    "    # (3) ìµœì¢… ë‹µë³€ ìƒì„±\n",
    "    tool_messages_text = \"\\n\\n\".join(tool_messages)\n",
    "    final_response = (prompt | llm).invoke({\n",
    "        \"input\": user_input,\n",
    "        \"tool_messages\": tool_messages_text\n",
    "    })\n",
    "\n",
    "    return final_response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79a5e0",
   "metadata": {},
   "source": [
    "#### 4. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856cdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain, RunnableConfig\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ ì¹´í˜ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "@chain\n",
    "def cafe_tool_chain(user_input: str, config: RunnableConfig):\n",
    "    ai_msg = (prompt | llm_with_tools).invoke({\"input\": user_input}, config=config)\n",
    "\n",
    "    tool_messages = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        args = tool_call[\"args\"]\n",
    "\n",
    "        if tool_name == \"db_search_cafe_func\":\n",
    "            tool_messages.append(db_search_cafe_func.invoke(args))\n",
    "        elif tool_name == \"wiki_summary\":\n",
    "            tool_messages.append(wiki_summary.invoke(args))\n",
    "        elif tool_name == \"tavily_search\":\n",
    "            tool_messages.append(tavily_search_func.invoke(args))\n",
    "\n",
    "    final_response = (prompt | llm).invoke({\n",
    "        \"input\": user_input,\n",
    "        \"tool_messages\": tool_messages\n",
    "    })\n",
    "\n",
    "    return final_response.content\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
